{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font style = \"color:rgb(50,120,229)\">Introduction</font>\n",
    "\n",
    "> <font style=\"font-family:Poiret one\" size = \"+2\">\"AI has succeeded in doing almost everything that requires ‘thinking’ but has failed to do what people do without thinking\" - Prof. Donald Knuth</font>\n",
    "\n",
    "Such is the tragedy of AI! But things are changing fast. \n",
    "\n",
    "Facial Recognition is one of those tasks that humans do without thinking. Part of the reason for this is that humans have dedicated hardware for face processing. \n",
    "\n",
    "How do we know this? In 1947, German neurologist, Joachim Bodamer described the case of a 24-year-old man who was shot in the head. He survived the injury but lost the ability to recognize people ( including himself ) by their faces. He could see perfectly fine and was able to recognize people by their gait ( style of walking ) and other mannerisms, but not by their faces! In other words, while his eyes were fine, the part of his brain involved in face processing was damaged while other parts of the brain were function just fine. This condition is called face blindness ( Prosopagnosia ). \n",
    "\n",
    "We will learn to do in software what even the human brain seems to do in hardware! \n",
    "\n",
    "# <font style = \"color:rgb(50,120,229)\">Face Recognition : Basic Intuition and History</font>\n",
    "We don’t yet have detailed information on how our brain works. Ongoing research in neurology suggests some ideas on how our brain most likely analyzes, store and retrieves information. \n",
    "\n",
    "[David Hubel](https://en.wikipedia.org/wiki/David_H._Hubel) and [Torsten Wiesel](https://en.wikipedia.org/wiki/Torsten_Wiesel) showed through experiments that nerve cells in primary visual cortex respond to specific local features of a scene, such as lines, edges, angles or movement. Our visual cortex then probably combines this information on lines, edges and angles to higher level information such as texture, shape and size. This information about texture, shape, size and color is combined to generate higher level representation of an object. This representation is used to classify a new face.\n",
    "\n",
    "How do humans recognize faces? We do not analyse each and every pixel of an image. We try to identify unique features on the face and compare it with someone we already know. For example, we can just look at the upper region of the face and tell if it is Donald Trump or not. Isn’t it? If we don’t know the person yet, we try to remember the unique features of the person until next time.\n",
    "\n",
    "| <img src=\"https://www.learnopencv.com/wp-content/uploads/2019/04/donald_trump_eyes.jpg\" alt=\"Input Image\" width=\"600\" height=\"600\"/> |\n",
    "| --- |\n",
    "| <center>Can you tell who this person is?</center> |\n",
    "\n",
    "Can a computer do the same? It cannot just compare two image parts. Even sight change in view-point or illumination is enough to ruin the comparison result if you compare raw pixel intensities. The computer needs something more meaningful and robust as a comparison metric.\n",
    "\n",
    "Taking inspiration from the human visual system, Computer Vision researchers have tried to come up with different features to efficiently describe the uniqueness in each persons face. The simplest of features can be mean and variance of face pixel intensities, ratio of height:width of the face etc. There are hundreds of published papers which propose different features.\n",
    "\n",
    "| <img src=\"https://www.learnopencv.com/wp-content/uploads/2019/04/Screen-Shot-2019-04-16-at-9.05.12-AM.png\" alt=\"Input Image\" width=\"600\" height=\"600\"/> |\n",
    "| --- |\n",
    "| <center>Facial Feature Extraction using Statistical heuristics</center> |\n",
    "\n",
    "Some notable algorithms like Eigen Faces, Fischer Faces, LBPH try to apply mathematical tricks ( like PCA, LDA, Histograms etc ) to represent the face in a more compact form by extracting the most useful information ( features ) from the face and getting rid of redundant information.\n",
    "\n",
    "| <img src=\"https://www.learnopencv.com/wp-content/uploads/2018/01/opcv4face-w7-m5-FeatureHistogramFaceImage.jpg\" alt=\"Input Image\" width=\"600\" height=\"600\"/> |\n",
    "| --- |\n",
    "| <center>Feature extraction using LBP Histograms</center> |\n",
    "\n",
    "With the advent of Deep Learning, these hand-crafted features have taken a backseat and researchers have now tasked CNNs for finding the right features for them. We will discuss this approach in more details in the next sections.\n",
    "\n",
    "### <font style=\"color:rgb(8,133,37)\">*It is all about finding a good set of features to represent the face and then it can be as simple as distinguishing between apples and oranges.*</font>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
